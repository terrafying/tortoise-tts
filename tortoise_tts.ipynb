{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tortoise-tts.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Welcome to Tortoise! ğŸ¢ğŸ¢ğŸ¢ğŸ¢\n",
        "\n",
        "Before you begin, I **strongly** recommend you turn on a GPU runtime.\n",
        "\n",
        "There's a reason this is called \"Tortoise\" - this model takes up to a minute to perform inference for a single sentence on a GPU. Expect waits on the order of hours on a CPU."
      ],
      "metadata": {
        "id": "_pIZ3ZXNp7cf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrK20I32grP6"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/jnordberg/tortoise-tts.git\n",
        "%cd tortoise-tts\n",
        "!pip3 install transformers==4.19.0\n",
        "!pip3 install -r requirements.txt\n",
        "\n",
        "!pip3 install einops==0.5.0\n",
        "!pip3 install rotary_embedding_torch==0.1.5\n",
        "!pip3 install unidecode==1.3.5\n",
        "\n",
        "!python3 setup.py install"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt -y install youtube-dl ffmpeg\n",
        "!python3 -m pip install --force-reinstall https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz"
      ],
      "metadata": {
        "id": "dj0UKOGxnu7f",
        "outputId": "d61db6b6-9054-48ba-a4c8-bdc455293dff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "youtube-dl is already the newest version (2020.03.24-1).\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz\n",
            "  Downloading https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz (2.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mutagen (from yt-dlp==2023.3.4)\n",
            "  Downloading mutagen-1.46.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex (from yt-dlp==2023.3.4)\n",
            "  Downloading pycryptodomex-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets (from yt-dlp==2023.3.4)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi (from yt-dlp==2023.3.4)\n",
            "  Downloading certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m157.0/157.0 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli (from yt-dlp==2023.3.4)\n",
            "  Downloading Brotli-1.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: yt-dlp\n",
            "  Building wheel for yt-dlp (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yt-dlp: filename=yt_dlp-2023.3.4-py2.py3-none-any.whl size=2716620 sha256=ceae1922a00b9f25a8ed207f5f325c0fd5adb9c25019a62fcfffd940b7041413\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pfe31kap/wheels/4c/91/d1/c5369304e2f7afb660bb6eee093af5a7d3c0ea05a3c1e8c797\n",
            "Successfully built yt-dlp\n",
            "Installing collected packages: brotli, websockets, pycryptodomex, mutagen, certifi, yt-dlp\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2022.12.7\n",
            "    Uninstalling certifi-2022.12.7:\n",
            "      Successfully uninstalled certifi-2022.12.7\n",
            "Successfully installed brotli-1.0.9 certifi-2023.5.7 mutagen-1.46.0 pycryptodomex-3.18.0 websockets-11.0.3 yt-dlp-2023.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/tortoise-tts\n",
        "# Imports used through the rest of the notebook.\n",
        "import torch\n",
        "import torchaudio\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import IPython\n",
        "\n",
        "from tortoise.api import TextToSpeech\n",
        "from tortoise.utils.audio import load_audio, load_voice, load_voices\n",
        "\n",
        "# This will download all the models used by Tortoise from the HF hub.\n",
        "tts = TextToSpeech()"
      ],
      "metadata": {
        "id": "Gen09NM4hONQ",
        "outputId": "98367a22-43b3-41f6-ce0a-e187731db699",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tortoise-tts\n",
            "Downloading autoregressive.pth from https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/autoregressive.pth...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100% (1716988501 of 1716988501) |########| Elapsed Time: 0:00:06 Time:  0:00:06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n",
            "Downloading classifier.pth from https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/classifier.pth...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100% (60938957 of 60938957) |############| Elapsed Time: 0:00:00 Time:  0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n",
            "Downloading clvp2.pth from https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/clvp2.pth...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100% (975620731 of 975620731) |##########| Elapsed Time: 0:00:08 Time:  0:00:08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n",
            "Downloading cvvp.pth from https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/cvvp.pth...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65% (99540992 of 151223901) |#######    | Elapsed Time: 0:00:00 ETA:   0:00:00"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the text that will be spoken.\n",
        "text = \"Joining two modalities results in a surprising increase in generalization! What would happen if we combined them all?\"\n",
        "\n",
        "# Here's something for the poetically inclined.. (set text=)\n",
        "\"\"\"\n",
        "Then took the other, as just as fair,\n",
        "And having perhaps the better claim,\n",
        "Because it was grassy and wanted wear;\n",
        "Though as for that the passing there\n",
        "Had worn them really about the same,\"\"\"\n",
        "\n",
        "# Pick a \"preset mode\" to determine quality. Options: {\"ultra_fast\", \"fast\" (default), \"standard\", \"high_quality\"}. See docs in api.py\n",
        "preset = \"fast\""
      ],
      "metadata": {
        "id": "bt_aoxONjfL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/tortoise-tts/tortoise/voices/gec\n",
        "!yt-dlp -x https://www.youtube.com/watch\\?v\\=nQW3uXpngzs --format mp4\n",
        "!ffmpeg -i 100\\ gecs\\ -\\ hand\\ crushed\\ by\\ a\\ mallet\\ \\(Acapella\\ -\\ Vocals\\ only\\)\\ \\[nQW3uXpngzs\\].m4a -c:v copy -c:a libmp3lame -q:a 4 100-gecs-hand-crushed-by-a-mallet-ACAPELLLA.mp3\n"
      ],
      "metadata": {
        "id": "FB8Yo92jsWOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/tortoise-tts/tortoise/voices/gec\n",
        "!ffmpeg -ss 00:00:00 -t 00:00:10.00 -i 100-gecs-hand-crushed-by-a-mallet-ACAPELLLA.mp3 1.mp3\n",
        "!ffmpeg -ss 00:00:10 -t 00:00:10.00 -i 100-gecs-hand-crushed-by-a-mallet-ACAPELLLA.mp3 2.mp3\n",
        "!ffmpeg -ss 00:00:20 -t 00:00:10.00 -i 100-gecs-hand-crushed-by-a-mallet-ACAPELLLA.mp3 3.mp3"
      ],
      "metadata": {
        "id": "TPXT5bhatRgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tortoise will attempt to mimic voices you provide. It comes pre-packaged\n",
        "# with some voices you might recognize.\n",
        "\n",
        "# Let's list all the voices available. These are just some random clips I've gathered\n",
        "# from the internet as well as a few voices from the training dataset.\n",
        "# Feel free to add your own clips to the voices/ folder.\n",
        "%ls tortoise/voices\n",
        "\n",
        "IPython.display.Audio('100-gecs-hand-crushed-by-a-mallet-ACAPELLLA.mp3')"
      ],
      "metadata": {
        "id": "SSleVnRAiEE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/tortoise-tts/\n",
        "# Pick one of the voices from the output above\n",
        "voice = 'gec'\n",
        "\n",
        "# Load it and send it through Tortoise.\n",
        "voice_samples, conditioning_latents = load_voice(voice)\n",
        "gen = tts.tts_with_preset(text, voice_samples=voice_samples, conditioning_latents=conditioning_latents, \n",
        "                          preset=preset)\n",
        "torchaudio.save('generated.wav', gen.squeeze(0).cpu(), 24000)\n",
        "IPython.display.Audio('generated.wav')"
      ],
      "metadata": {
        "id": "KEXOKjIvn6NW",
        "outputId": "478a78b3-b586-476f-9068-2a2891893316",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tortoise-tts\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-8bd26e473ffa>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load it and send it through Tortoise.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mvoice_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconditioning_latents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_voice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m gen = tts.tts_with_preset(text, voice_samples=voice_samples, conditioning_latents=conditioning_latents, \n\u001b[0m\u001b[1;32m      8\u001b[0m                           preset=preset)\n\u001b[1;32m      9\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'generated.wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tts' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tortoise can also generate speech using a random voice. The voice changes each time you execute this!\n",
        "# (Note: random voices can be prone to strange utterances)\n",
        "gen = tts.tts_with_preset(text, voice_samples=None, conditioning_latents=None, preset=preset)\n",
        "torchaudio.save('generated.wav', gen.squeeze(0).cpu(), 24000)\n",
        "IPython.display.Audio('generated.wav')"
      ],
      "metadata": {
        "id": "16Xs2SSC3BXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can also combine conditioning voices. Combining voices produces a new voice\n",
        "# with traits from all the parents.\n",
        "#\n",
        "# Lets see what it would sound like if Picard and Kirk had a kid with a penchant for philosophy:\n",
        "voice_samples, conditioning_latents = load_voices(['pat', 'william'])\n",
        "\n",
        "gen = tts.tts_with_preset(\"They used to say that if man was meant to fly, heâ€™d have wings. But he did fly. He discovered he had to.\", \n",
        "                          voice_samples=None, conditioning_latents=None, preset=preset)\n",
        "torchaudio.save('captain_kirkard.wav', gen.squeeze(0).cpu(), 24000)\n",
        "IPython.display.Audio('captain_kirkard.wav')"
      ],
      "metadata": {
        "id": "fYTk8KUezUr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del tts  # Will break other cells, but necessary to conserve RAM if you want to run this cell.\n",
        "\n",
        "# Tortoise comes with some scripts that does a lot of the lifting for you. For example,\n",
        "# read.py will read a text file for you.\n",
        "!python3 tortoise/read.py --voice=train_atkins --textfile=tortoise/data/riding_hood.txt --preset=ultra_fast --output_path=.\n",
        "\n",
        "IPython.display.Audio('train_atkins/combined.wav')\n",
        "# This will take awhile.."
      ],
      "metadata": {
        "id": "t66yqWgu68KL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}